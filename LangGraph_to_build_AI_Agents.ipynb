{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMqld3YFXQvxWZroZ70huiC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kumarvels/GenAIProjects/blob/main/LangGraph_to_build_AI_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Building an AI Agent with LangGraph in Google Colab\n",
        "# Usecase for to build a simple AI agent using LangGraph to calculate solar  panel energy savings\n",
        "This notebook demonstrates how to build a simple AI agent using LangGraph to calculate solar panel energy savings. The agent will:\n",
        "- Interact with the user to gather inputs (e.g., electricity cost).\n",
        "- Use a tool node to compute savings.\n",
        "- Display the results.\n",
        "\n"
      ],
      "metadata": {
        "id": "2hBhI2ihitPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: Install Required Libraries\n",
        "\n",
        "Step 2.1: Install LangChain, LangGraph, and Other Dependencies\n",
        "In a new code cell, run the following command to install the required libraries\n",
        "\n",
        "Explanation:\n",
        "langchain: Core library for building language model workflows.\n",
        "\n",
        "langgraph: Extension for creating stateful, multi-agent workflows with cycles.\n",
        "\n",
        "langchain-community: Community-contributed tools and integrations.\n",
        "\n",
        "langchain-core: Core components of LangChain.\n",
        "\n",
        "langchain-openai: Integration with OpenAI models (we’ll use this for the language model).\n",
        "\n",
        "python-dotenv: For managing environment variables (e.g., API keys).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ge_jyLHmjq_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UuBx98CcOPC"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langgraph langchain-community langchain-core langchain-openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2.2: Install Additional Tools (Optional)\n",
        "\n",
        "If you plan to use Google’s Gemini model, you’ll need the Google Generative AI package\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5O1cDPMAkWz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "id": "nzoYJG9ekkey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2.3: Verify Installation\n",
        "\n",
        "Add a code cell to check the installed versions\n",
        "\n",
        "LangChain and LangGraph are frameworks for building applications that use large language models (LLMs), but they differ in their approach to workflow management.\n",
        "\n",
        "LangChain is designed for simple, linear workflows\n",
        "\n",
        "LangGraph focuses on complex, graph-based workflows, making it suitable for agentic and multi-actor scenarios\n",
        "\n",
        "Key Differences:\n",
        "\n",
        "Workflow Architecture:\n",
        "LangChain uses a linear, chain-based architecture, while LangGraph uses a graph-based architecture, allowing for more complex and dynamic workflows.\n",
        "\n",
        "Agentic Systems:\n",
        "LangGraph is particularly well-suited for building agentic systems, where multiple agents interact and collaborate, while LangChain is more focused on simpler, sequential tasks.\n",
        "\n",
        "State Management:\n",
        "LangGraph provides built-in support for managing state, which is crucial for complex workflows where context and information need to be carried across different steps.\n",
        "\n",
        "Flexibility:\n",
        "LangGraph offers greater flexibility and control over workflow design, allowing for dynamic branching, loops, and other complex control flow patterns.\n",
        "\n",
        "Scalability:\n",
        "Both frameworks are designed to be scalable, but LangGraph's graph-based architecture allows for more easily handling complex workflows with multiple agents and interactions."
      ],
      "metadata": {
        "id": "uulBivvVmQnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import langgraph\n",
        "print(\"LangChain version:\", langchain.__version__)"
      ],
      "metadata": {
        "id": "aaM3sCRLmaGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3: Set Up API Keys and Environment Variables\n",
        "\n",
        "Step 3.1: Obtain an OpenAI API Key\n",
        "Go to OpenAI, sign up/log in, and generate an API key.\n",
        "\n",
        "Alternatively, if using Google’s Gemini model, get an API key from Google AI Studio.\n",
        "\n",
        "Step 3.2: Store the API Key Securely in Colab\n",
        "Use Google Colab’s user input feature to securely input your API key without hardcoding it\n",
        "\n"
      ],
      "metadata": {
        "id": "CDyOAsL4o8_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# Prompt for OpenAI API key\n",
        "# openai_api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "# os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "# If using Google Gemini, uncomment the following:\n",
        "google_api_key = getpass(\"Enter your Google API key: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_api_key"
      ],
      "metadata": {
        "id": "NsdHG-DspBiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4: Define the State and Tools for the AI Agent\n",
        "\n",
        "Step 4.1: Import Required Modules\n",
        "Add a code cell to import the necessary LangChain and LangGraph components\n",
        "\n"
      ],
      "metadata": {
        "id": "Ue10X2qW2UPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.tools import tool"
      ],
      "metadata": {
        "id": "uOAvVtmn6HsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2: Define the State\n",
        "\n",
        "LangGraph uses a state to keep track of the agent’s progress. Define a state class to store messages and user inputs\n",
        "\n",
        "Explanation:\n",
        "\n",
        "messages: A list of conversation messages (human and AI).\n",
        "\n",
        "electricity_cost: The user’s electricity cost per kWh (to be provided by the user).\n",
        "\n",
        "savings: The calculated savings from using solar panels.\n",
        "\n",
        "Annotated with operator.add allows messages to be appended to the list.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rfg0582z67YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    electricity_cost: float  # Store the user's electricity cost\n",
        "    savings: float  # Store the calculated savings"
      ],
      "metadata": {
        "id": "UKdRVmYC692v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3: Create a Tool for Calculating Solar Savings\n",
        "\n",
        "Define a tool that calculates potential savings based on the user’s electricity cost\n",
        "\n",
        "Explanation:\n",
        "\n",
        "The @tool decorator makes this function a LangChain tool.\n",
        "\n",
        "We assume a 5 kW solar system produces 20 kWh/day (a rough estimate).\n",
        "\n",
        "Savings are calculated as: yearly production (kWh) × cost per kWh.\n",
        "\n"
      ],
      "metadata": {
        "id": "HUkp3UogHGV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any\n",
        "import inspect\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define a Pydantic model for the tool's input\n",
        "class SolarSavingsInput(BaseModel):\n",
        "    electricity_cost: float = Field(description=\"The cost of electricity per kWh in dollars.\")\n",
        "\n",
        "# Remove the @tool decorator so the LLM doesn't see this as a callable tool\n",
        "# @tool\n",
        "def calculate_solar_savings_manual(args: SolarSavingsInput) -> float:\n",
        "    \"\"\"\n",
        "    Calculate potential solar panel savings based on electricity cost per kWh.\n",
        "    Accepts arguments as a SolarSavingsInput model.\n",
        "    Assumes a 5 kW solar system producing 20 kWh/day, 365 days/year.\n",
        "    This function is intended for manual execution in the tool_node.\n",
        "    \"\"\"\n",
        "    # Optional: Print function signature for debugging\n",
        "    print(f\"Debug: calculate_solar_savings_manual signature: {inspect.signature(calculate_solar_savings_manual)}\")\n",
        "\n",
        "\n",
        "    electricity_cost = args.electricity_cost # Access cost from the Pydantic model\n",
        "    try:\n",
        "        cost = float(electricity_cost)\n",
        "        if cost <= 0:\n",
        "             raise ValueError(\"Electricity cost must be positive.\")\n",
        "    except (ValueError, TypeError):\n",
        "        raise ValueError(f\"Invalid electricity cost provided: {electricity_cost}. Must be a number.\")\n",
        "\n",
        "    daily_production = 20  # kWh per day\n",
        "    yearly_production = daily_production * 365  # kWh per year\n",
        "    savings = yearly_production * cost  # Yearly savings in dollars\n",
        "    return round(savings, 2)"
      ],
      "metadata": {
        "id": "9z0SW7IXHI2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5: Build the LangGraph Workflow\n",
        "\n",
        "Step 5.1: Initialize the Language Model\n",
        "Set up the language model (e.g., OpenAI’s GPT,  Google Gemini Pro/Flash models)\n",
        "\n"
      ],
      "metadata": {
        "id": "-GXHvBYbHVXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "# llm_with_tools = llm.bind_tools([calculate_solar_savings])\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0, google_api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "# Remove the tool binding as we are manually handling the tool execution\n",
        "# llm_with_tools = llm.bind_tools([calculate_solar_savings])\n",
        "llm_with_tools = llm # Use the plain LLM without tools bound\n",
        "print(\"Google Gemini model initialized.\")"
      ],
      "metadata": {
        "id": "REBelfUCI8HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6: Define the Assistant and Tool Nodes\n",
        "\n",
        "What: Create the nodes for the LangGraph workflow (assistant and tool nodes).\n",
        "\n",
        "Why: Nodes represent the steps in the agent's workflow: interaction (assistant) and computation (tool).\n",
        "\n",
        "How: Define functions for each node to handle user input and tool execution.\n",
        "\n",
        "Outcome: The agent can interact with the user and calculate savings in a structured workflow.\n"
      ],
      "metadata": {
        "id": "T45vSWnsJklX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolMessage # Import ToolMessage\n",
        "# Removed: import inspect (not needed in this cell)\n",
        "# Removed: from pydantic import BaseModel, Field (SolarSavingsInput is defined in 9z0SW9IXHI2b)\n",
        "\n",
        "# The SolarSavingsInput Pydantic model is defined in cell 9z0SW9IXHI2b.\n",
        "# The @tool calculate_solar_savings function was previously defined and bound, but\n",
        "# we are now removing the @tool decorator in cell 9z0SW7IXHI2b and handling\n",
        "# the calculation manually in the tool_node.\n",
        "\n",
        "# Removed the redundant definition of calculate_solar_savings and SolarSavingsInput\n",
        "# from this cell. They are defined in cell 9z0SW7IXHI2b.\n",
        "\n",
        "\n",
        "def assistant_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    Assistant node: Handles user interaction, attempts to parse electricity cost,\n",
        "    and invokes the language model if necessary.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    electricity_cost = state.get(\"electricity_cost\", None)\n",
        "\n",
        "    # If electricity_cost is not set, try to parse it from the last human message\n",
        "    if electricity_cost is None:\n",
        "        last_human_message = None\n",
        "        # Find the latest human message\n",
        "        for msg in reversed(messages):\n",
        "            if isinstance(msg, HumanMessage):\n",
        "                last_human_message = msg\n",
        "                break\n",
        "\n",
        "        if last_human_message:\n",
        "            try:\n",
        "                # Attempt to parse the content as a float\n",
        "                cost = float(last_human_message.content)\n",
        "                if cost > 0:\n",
        "                    # If successful and positive, update the state with the parsed cost\n",
        "                    print(f\"Parsed electricity cost: {cost}. Updating state.\") # Debug print\n",
        "                    # Return the state with the updated electricity_cost, without involving the LLM\n",
        "                    return {\n",
        "                        \"messages\": messages, # Do not add a tool call message here\n",
        "                        \"electricity_cost\": cost, # Update the state\n",
        "                        \"savings\": state.get(\"savings\", 0.0)\n",
        "                    }\n",
        "                else:\n",
        "                     # If not positive, add a message asking for a positive value\n",
        "                    print(\"Parsed non-positive cost, asking again.\") # Debug print\n",
        "                    # In this case, we still involve the LLM to generate the response asking for a positive value\n",
        "                    response = llm_with_tools.invoke(messages + [AIMessage(content=\"Please provide a positive electricity cost per kWh (in dollars).\")])\n",
        "                    return {\n",
        "                        \"messages\": messages + [response],\n",
        "                        \"electricity_cost\": None, # Keep it None as valid cost wasn't provided\n",
        "                        \"savings\": state.get(\"savings\", 0.0)\n",
        "                    }\n",
        "            except (ValueError, TypeError):\n",
        "                # If parsing fails, proceed to involve the LLM\n",
        "                print(\"Parsing failed, involving LLM.\") # Debug print\n",
        "                pass # Continue below to involve LLM\n",
        "\n",
        "\n",
        "    # If electricity_cost is already set (meaning we've already parsed it and likely generated a tool call),\n",
        "    # or if parsing failed and we need the LLM to respond to the initial query or an unparseable input.\n",
        "    # Involve the LLM to generate the next message.\n",
        "    print(\"Invoking LLM.\") # Debug print\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": messages + [response]}\n",
        "\n",
        "\n",
        "def tool_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    Tool node: Executes the solar savings calculation based on the electricity cost\n",
        "    provided in the state. Manually performs the calculation using the function\n",
        "    defined in cell 9z0SW7IXHI2b.\n",
        "    \"\"\"\n",
        "    print(\"Entering tool_node.\") # Debug print\n",
        "    messages = state[\"messages\"]\n",
        "    electricity_cost = state.get(\"electricity_cost\")\n",
        "\n",
        "    if electricity_cost is not None:\n",
        "        try:\n",
        "            # Manually extract and validate the electricity_cost from the state\n",
        "            cost = float(electricity_cost)\n",
        "            if cost <= 0:\n",
        "                 raise ValueError(\"Electricity cost must be positive.\")\n",
        "\n",
        "            # Use the manual calculation function defined in cell 9z0SW7IXHI2b\n",
        "            # We need to pass the cost as a SolarSavingsInput object\n",
        "            savings = calculate_solar_savings_manual(args=SolarSavingsInput(electricity_cost=cost))\n",
        "\n",
        "            # Create a message with the result\n",
        "            result_message = AIMessage(content=f\"Based on your electricity cost of ${cost} per kWh, the estimated yearly solar panel savings are ${savings}.\")\n",
        "            print(f\"Calculated savings: ${savings}\") # Debug print\n",
        "\n",
        "\n",
        "            # Update the state with the calculated savings and the cost used\n",
        "            return {\n",
        "                \"messages\": messages + [result_message],\n",
        "                \"electricity_cost\": cost, # Keep the cost in state\n",
        "                \"savings\": savings\n",
        "            }\n",
        "        except Exception as e:\n",
        "            # Handle errors during manual calculation or argument extraction/validation\n",
        "            error_message = AIMessage(content=f\"Error processing electricity cost or performing calculation: {e}\")\n",
        "            print(f\"Error in tool_node during manual calculation: {e}\") # Debug print\n",
        "            return {\"messages\": messages + [error_message]}\n",
        "    else:\n",
        "        # This case should ideally not happen if routed correctly by should_continue\n",
        "        print(\"Electricity cost not found in state in tool_node.\") # Debug print\n",
        "        return {\"messages\": messages + [AIMessage(content=\"Could not find electricity cost in the state to perform calculation.\")]}\n",
        "\n",
        "\n",
        "print(\"Nodes defined.\")"
      ],
      "metadata": {
        "id": "dptiL8RNJrIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7: Build and Compile the LangGraph Workflow\n",
        "  \n",
        "What: Construct the LangGraph workflow by connecting nodes with edges.\n",
        "\n",
        "Why: The workflow defines the agent's behavior: start with the assistant, move to the tool, and end.\n",
        "\n",
        "How: Use StateGraph to add nodes, set the entry point, and define conditional edges.\n",
        "\n",
        "Outcome: A compiled graph ready to process user inputs and calculate savings.\n"
      ],
      "metadata": {
        "id": "gFk3z7_7KCOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"assistant\", assistant_node)\n",
        "builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Define the entry point\n",
        "builder.set_entry_point(\"assistant\")\n",
        "\n",
        "# Define a function to decide whether to continue or end\n",
        "def should_continue(state: AgentState) -> str:\n",
        "    # If electricity_cost is set in the state, move to tools\n",
        "    if state.get(\"electricity_cost\") is not None:\n",
        "        print(\"Routing to tools node based on electricity_cost in state.\") # Debug print\n",
        "        return \"tools\"\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    # If the assistant returned a tool call (which shouldn't happen with the fix),\n",
        "    # or if the last message is from the assistant and does not have tool calls,\n",
        "    # it means the assistant has responded with a non-tool call message, so we end.\n",
        "    # If the last message is a HumanMessage, the assistant node will be called again.\n",
        "    if isinstance(last_message, AIMessage) and not last_message.tool_calls:\n",
        "         print(\"Routing to end as assistant responded without tool calls.\") # Debug print\n",
        "         return \"end\"\n",
        "    # Otherwise, continue to the assistant node (e.g., if the last message was HumanMessage)\n",
        "    else:\n",
        "        print(\"Routing back to assistant.\") # Debug print\n",
        "        return \"assistant\"\n",
        "\n",
        "\n",
        "# Add conditional edge from assistant\n",
        "builder.add_conditional_edges(\n",
        "    \"assistant\",\n",
        "    should_continue,\n",
        "    {\"tools\": \"tools\", \"end\": END, \"assistant\": \"assistant\"} # Add 'assistant' as a possible route\n",
        ")\n",
        "\n",
        "# Add edge from tools to end\n",
        "builder.add_edge(\"tools\", END)\n",
        "\n",
        "# Compile the graph\n",
        "graph = builder.compile()\n",
        "print(\"Graph compiled successfully.\")"
      ],
      "metadata": {
        "id": "VFUDAteUKD_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8: Run the AI Agent\n",
        "\n",
        "What: Simulate a user interaction to test the AI agent.\n",
        "\n",
        "Why: Running the agent demonstrates its functionality and ensures it works as expected.\n",
        "\n",
        "How: Provide an initial message, run the graph, and simulate providing the electricity cost.\n",
        "\n",
        "Outcome: The agent prompts for the cost, calculates savings, and displays the result (e.g., $1095 for $0.15/kWh).\n"
      ],
      "metadata": {
        "id": "qPbQe996LWMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Start the conversation - User asks to calculate savings\n",
        "initial_state = {\n",
        "    \"messages\": [HumanMessage(content=\"I want to calculate my solar panel savings.\")],\n",
        "    \"electricity_cost\": None,\n",
        "    \"savings\": 0.0\n",
        "}\n",
        "\n",
        "print(\"\\n--- First Interaction ---\")\n",
        "# Use list(graph.stream(initial_state)) to collect all events\n",
        "events1 = list(graph.stream(initial_state))\n",
        "for event in events1:\n",
        "    for key, value in event.items():\n",
        "        print(f\"Node: {key}\")\n",
        "        if \"messages\" in value:\n",
        "            # Print the content of the latest message\n",
        "            print(value[\"messages\"][-1].content)\n",
        "        if \"electricity_cost\" in value:\n",
        "            print(f\"Electricity Cost: {value['electricity_cost']}\")\n",
        "        if \"savings\" in value:\n",
        "             print(f\"Savings: {value['savings']}\")\n",
        "\n",
        "\n",
        "# Step 2: Continue the conversation - User provides the electricity cost\n",
        "# To simulate the next turn, we need the final state from the previous interaction.\n",
        "# The last event in events1 contains the final state after the first interaction.\n",
        "last_event_step1 = events1[-1]\n",
        "# Get the state from the last event by accessing the dictionary value\n",
        "# The key might be a node name or END\n",
        "last_state_step1 = list(last_event_step1.values())[0]\n",
        "\n",
        "\n",
        "print(\"\\n--- Second Interaction (with cost provided) ---\")\n",
        "# Now, add the user's response with the cost to the messages from the previous state\n",
        "state_with_cost = {\n",
        "    \"messages\": last_state_step1[\"messages\"] + [HumanMessage(content=\"0.15\")],\n",
        "    \"electricity_cost\": last_state_step1[\"electricity_cost\"], # This should still be None from step 1\n",
        "    \"savings\": last_state_step1[\"savings\"]\n",
        "}\n",
        "\n",
        "# Use list(graph.stream(state_with_cost)) to collect all events for the second interaction\n",
        "events2 = list(graph.stream(state_with_cost))\n",
        "for event in events2:\n",
        "    for key, value in event.items():\n",
        "        print(f\"Node: {key}\")\n",
        "        if \"messages\" in value:\n",
        "            # Print the content of the latest message\n",
        "            print(value[\"messages\"][-1].content)\n",
        "        if \"electricity_cost\" in value:\n",
        "            print(f\"Electricity Cost: {value['electricity_cost']}\")\n",
        "        if \"savings\" in value:\n",
        "             print(f\"Savings: {value['savings']}\")"
      ],
      "metadata": {
        "id": "jUXI7rooLbEq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}