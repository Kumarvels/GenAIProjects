{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPgS5q0nSAj8YUP3R8k8OOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kumarvels/GenAIProjects/blob/main/CTFAgent_Pentesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paper CTFAgent: Penetration Testing AUtomation**\n",
        "\n",
        "The paper titled \"Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges\" (arXiv:2506.17644), addresses a significant cybersecurity problem: the inability of large language models (LLMs) to effectively apply their technical knowledge to solve complex, dynamic, and interactive cybersecurity challenges, such as Capture-the-Flag (CTF) competitions.\n",
        "\n",
        "These competitions simulate real-world hacking scenarios where participants must identify vulnerabilities, exploit them, and retrieve hidden \"flags\" (unique text strings) to demonstrate their skills. The paper highlights that while LLMs possess vast theoretical knowledge, they struggle to translate this into practical, actionable solutions in such environments, particularly due to limitations in contextual reasoning and interaction with live systems.\n",
        "\n"
      ],
      "metadata": {
        "id": "96Vy0KR3gHfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aDnsznw_mNEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CTFAgent Prototype in Google Colab\n",
        "\n",
        "# Step 1: Install required libraries and setup Ollama\n",
        "# This will install all necessary Python packages.\n",
        "!pip install langchain transformers sentence-transformers chromadb ollama langchain-community -q\n",
        "\n",
        "# Download and install Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "# Start the Ollama server in the background.\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "\n",
        "# It's recommended to run Ollama on a GPU instance in Colab for better performance.\n",
        "# Make sure to change the runtime type to include a GPU.\n",
        "command = \"ollama serve\"\n",
        "process = subprocess.Popen(command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "print(\"Starting Ollama server...\")\n",
        "# Give the server a moment to start up\n",
        "time.sleep(5)\n",
        "\n",
        "# Pull the required model. Here we use llama3.\n",
        "!ollama pull llama3\n",
        "print(\"Ollama server and model are ready.\")\n",
        "\n",
        "\n",
        "# Step 2: Import necessary libraries\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Step 3: Set up the RAG Knowledge Base\n",
        "# Sample cybersecurity knowledge (simplified vulnerability data)\n",
        "knowledge_base = \"\"\"\n",
        "Buffer Overflow: Occurs when a program attempts to write more data to a buffer than the buffer can hold. This can overwrite adjacent memory, leading to a crash or execution of arbitrary code. A common exploit involves overwriting the return address on the stack with the address of malicious shellcode.\n",
        "SQL Injection: A code injection technique that might destroy your database. SQL Injection is one of the most common web hacking techniques. It is the placement of malicious code in SQL statements, via web page input. A common exploit to bypass authentication is to use ' OR 1=1 --.\n",
        "\"\"\"\n",
        "\n",
        "# Split the knowledge base into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "texts = text_splitter.split_text(knowledge_base)\n",
        "\n",
        "# Create embeddings for the text chunks\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Create a Chroma vector store from the texts and embeddings\n",
        "vectorstore = Chroma.from_texts(texts, embeddings)\n",
        "\n",
        "# Initialize the LLM (using the running Ollama instance)\n",
        "llm = Ollama(model=\"llama3\")\n",
        "\n",
        "# Create a RetrievalQA chain for vulnerability identification\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Step 4: Define Agent Functions\n",
        "\n",
        "def generate_exploit(vulnerability):\n",
        "    \"\"\"Generates an exploit for a given vulnerability using the RAG chain.\"\"\"\n",
        "    query = f\"How can I exploit a {vulnerability} vulnerability?\"\n",
        "    result = qa_chain({\"query\": query})\n",
        "    return result['result']\n",
        "\n",
        "def simulate_command_execution(command):\n",
        "    \"\"\"Simulates the execution of a command in a sandboxed environment.\"\"\"\n",
        "    print(f\"\\nExecuting (simulated): {command}\")\n",
        "    # In a real-world scenario, this would interact with a secure, sandboxed environment.\n",
        "    if \"buffer overflow\" in command.lower():\n",
        "        return \"Flag retrieved: FLAG{BufferOverflowSuccess_1a2b3c}\"\n",
        "    elif \"sql injection\" in command.lower() or \"' or 1=1 --\" in command.lower():\n",
        "        return \"Flag retrieved: FLAG{SQLInjectionSuccess_4d5e6f}\"\n",
        "    else:\n",
        "        return \"No flag retrieved. The command was either invalid or did not succeed.\"\n",
        "\n",
        "# Step 5: Main Testing Loop\n",
        "\n",
        "def run_ctfagent_challenge(challenge_description):\n",
        "    \"\"\"Runs the full CTF agent workflow for a given challenge.\"\"\"\n",
        "    print(\"--- Starting CTF Challenge ---\")\n",
        "    print(f\"Challenge: {challenge_description}\")\n",
        "\n",
        "    # RAG-Understanding: Identify the vulnerability from the challenge description.\n",
        "    vulnerability_result = qa_chain({\"query\": challenge_description})\n",
        "    vulnerability = vulnerability_result['result']\n",
        "    print(f\"\\nIdentified Vulnerability: {vulnerability}\")\n",
        "\n",
        "    # RAG-Exploiting: Generate a potential exploit for the identified vulnerability.\n",
        "    exploit_suggestion = generate_exploit(vulnerability.split(\":\")[0]) # Extract the vulnerability type\n",
        "    print(f\"\\nGenerated Exploit: {exploit_suggestion}\")\n",
        "\n",
        "    # Interactive Augmentation: Execute and retrieve flag.\n",
        "    # In a real-world scenario, the agent would choose and execute commands based on the exploit_suggestion.\n",
        "    # Here, we simulate user input for the command.\n",
        "    command = input(\"Enter simulated command to execute exploit: \")\n",
        "    flag = simulate_command_execution(command)\n",
        "    print(f\"Result: {flag}\")\n",
        "\n",
        "# Example Challenge\n",
        "challenge = \"Analyze the following network service for vulnerabilities: A web application with a login form.\"\n",
        "run_ctfagent_challenge(challenge)"
      ],
      "metadata": {
        "id": "O5_d9HHPmNg0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}